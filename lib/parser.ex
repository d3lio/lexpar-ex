defmodule Lexpar.Parser do
  @moduledoc """
  LALR(1) parser generator in pure elixir.
  """

  defmacro __using__(opts) do
    entry = Keyword.get(opts, :entry)
    if entry === nil, do: raise "Must specify parser entry."

    quote do
      import Lexpar.Parser

      @doc """
      Parse given input with the grammatic generated by defnonterms.

      Usage:

      TODO
      """
      def parse(str) when is_binary(str) or is_list(str) do
        case __MODULE__.unquote(entry)(str, &iterator/1) do
          {ast, nil}    -> {:ok, ast}
          {ast, <<>>}   -> {:ok, ast}
          {ast, []}     -> {:ok, ast}
          {ast, source} -> {:err, "Unused input", source, ast}
          nil           -> {:err, "Input does not match", str, nil}
        end
      end

      @doc """
      Iterates over the given input for parsing.

      The default implementation is defined for strings and lists but can be overridden
      to use streams for example.

      If overridden it should define the following behaviour:
      1. For empty input as in eof it should return `nil`
      2. For single token input it should return `token`
      3. Otherwise it should return `{token, look-ahead-1, rest-of-input}`
      """
      defp iterator(nil), do: nil
      defp iterator(str) when is_binary(str) do
        case String.next_grapheme(str) do
          nil -> nil
          {head, tail} ->
            case String.first(tail) do
              nil -> head
              la -> {head, la, tail}
            end
        end
      end
      defp iterator([]), do: nil
      defp iterator([head]), do: head
      defp iterator([head, la | tail]), do: {head, la, [la | tail]}
    end
  end

  @doc """
  Defined a nonterminal for the parser to use.

  The simplest explanation in the case of this macro is that the nonterminal
  is a function that checks if a source input begins with a specific sequence
  of bytes/characters. For a detaild explanation read some papers on grammars.
  """
  defmacro defnonterm(name, do: block) do
    # IO.inspect({name, block})
    {nonterm_name, _, _} = name

    content = parse_block(block)

    IO.inspect([block, content])

    quote do
      @doc false
      def unquote(nonterm_name)(nil = source, iterator), do: iterator(source)
      def unquote(nonterm_name)(<<>> = source, iterator), do: iterator(source)
      def unquote(nonterm_name)([] = source, iterator), do: iterator(source)
      def unquote(nonterm_name)(source, iterator) do
        case iterator(source) do
          nil -> nil

        end

        # {head, la, rest} = iterator.(source)
        # IO.inspect([head, la])
        # __MODULE__.unquote(nonterm_name)(rest, iterator)
        unquote(content |> Enum.at(0) |> Kernel.elem(0))
      end
    end
  end

  def parse_block(block) do
    block |> Enum.map(&parse_rule/1)
  end

  def parse_rule(rule) do
    {:->, _, [head, logic]} = rule

    {terms, guard} = case head do
      [{:when, _, head}] -> head |> parse_head()
      terms -> {terms |> parse_terms(), nil}
    end

    {terms, guard |> parse_guard(), logic}
  end

  def parse_head(head) do
    [guard | terms] = head |> Enum.reverse()
    {terms |> Enum.reverse() |> parse_terms(), guard}
  end

  # TODO handle cases that are not `and` chains
  def parse_guard(nil), do: []
  def parse_guard(ast), do: parse_guard(ast, []) |> Enum.reverse()
  defp parse_guard({:and, _, [lhs, rhs]}, acc), do: parse_guard(lhs, [rhs | acc])
  defp parse_guard(check, acc), do: [check | acc]

  def parse_terms(terms) do
    terms |> Enum.map(&case &1 do
      {{:., _, [{ident, _, nil}, :*]}, _, _} -> {ident, :*}
      {{:., _, [{ident, _, nil}, :+]}, _, _} -> {ident, :+}
      {:@, _, [{:eps, ctx, nil}]} -> {:_, ctx, :eps}
      # term when is_tuple(term) -> raise "Invalid rule argument #{term}"
      term -> term
    end)
  end
end
